[
  {
    "objectID": "style/data_storage.html",
    "href": "style/data_storage.html",
    "title": "Data Storage",
    "section": "",
    "text": "All projects should be commited to version control, with a repository created in the Strategy Unit’s GitHub organisation.\nIdeally, any data that is used within the project should be part of a targets pipeline.\nThere are a number of considerations about whether to add the data to version control or not. At a high level:\n\nis the data OK to release publicly?\nis the data in a text-based (non-binary) format, such as .csv, .json (rather than say .xlsx)?\nis the data relatively small in size?\n\n\n\nIf data is grabbed from a website, or via an API, create code to download the file/data. Consider whether this is likely to be a stable way of getting the data (does the data change over time? do you suspect that the location of the resource may disappear? is it quick to retrieve the data?). If so, then it doesn’t make much sense to commit the data to version control as it can always be quickly regenerated.\n\n\n\nLarge files tend not to work particularly well with version control. Specifically, files larger than 100MB will be blocked by GitHub, and files larger than 50MB will generate a warning. But you may even want to class any file over a few MB as large.\nAlternatives for storing large files:\n\nif the file is something that is generated (and reproducible) from other sources, then do not bother tracking the file\nif the file is something that you want tracking with version control, look at git LFS\nif the file needs to be shared publicly, but LFS is not suitable, the file could be stored in Azure blob storage\nif the file needs to be shared privately, also consider Azure blob storage (using something like SAS tokens)\nif the file needs to only be shared within the Strategy Unit then store in SharePoint (i.e. within a teams channel)\n\nUse of network drives should be deprecated and avoided at all costs due to issues of lack of versioning of files and the performance bottleneck that is created by using a network share. If a network share is truly the only way of storing the data for sharing with colleagues, then look at using ways of syncing the file to local storage to avoid performance bottlenecks, such as robocopy."
  },
  {
    "objectID": "style/data_storage.html#data-from-websites",
    "href": "style/data_storage.html#data-from-websites",
    "title": "Data Storage",
    "section": "",
    "text": "If data is grabbed from a website, or via an API, create code to download the file/data. Consider whether this is likely to be a stable way of getting the data (does the data change over time? do you suspect that the location of the resource may disappear? is it quick to retrieve the data?). If so, then it doesn’t make much sense to commit the data to version control as it can always be quickly regenerated."
  },
  {
    "objectID": "style/data_storage.html#filesize",
    "href": "style/data_storage.html#filesize",
    "title": "Data Storage",
    "section": "",
    "text": "Large files tend not to work particularly well with version control. Specifically, files larger than 100MB will be blocked by GitHub, and files larger than 50MB will generate a warning. But you may even want to class any file over a few MB as large.\nAlternatives for storing large files:\n\nif the file is something that is generated (and reproducible) from other sources, then do not bother tracking the file\nif the file is something that you want tracking with version control, look at git LFS\nif the file needs to be shared publicly, but LFS is not suitable, the file could be stored in Azure blob storage\nif the file needs to be shared privately, also consider Azure blob storage (using something like SAS tokens)\nif the file needs to only be shared within the Strategy Unit then store in SharePoint (i.e. within a teams channel)\n\nUse of network drives should be deprecated and avoided at all costs due to issues of lack of versioning of files and the performance bottleneck that is created by using a network share. If a network share is truly the only way of storing the data for sharing with colleagues, then look at using ways of syncing the file to local storage to avoid performance bottlenecks, such as robocopy."
  },
  {
    "objectID": "style/git_and_github.html",
    "href": "style/git_and_github.html",
    "title": "Using git and GitHub",
    "section": "",
    "text": "Commits should be atomic\nAll code should be committed via pull request to main. Never push to main\n\nWorkflow for writing code with Git and GitHub:\n\nIf you haven’t already file an issue that describes what you are doing- whether it be fixing a bug, adding a feature, or something else\nMake a new branch to work on that feature. GitHub offers a button to do this automatically on the issue page, on the right hand side (see image)\nWork on the branch, pushing your code regularly to GitHub so it can be run and inspected when you are not around\nWhen it’s ready merge the branch to main. If you used the create branch button on GitHUb this will automatically close the issue. If the issue is not automatically closed, then close it manually\n\n\n\n\nTODO"
  },
  {
    "objectID": "style/git_and_github.html#preparing-a-package-release-of-your-code",
    "href": "style/git_and_github.html#preparing-a-package-release-of-your-code",
    "title": "Using git and GitHub",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "style/project_structure.html",
    "href": "style/project_structure.html",
    "title": "Project Structure",
    "section": "",
    "text": "as a package\nR/ for scripts\nsplit files into separate scripts\nuse {renv}\nuse {targets}\n\n\n\nRStudio projects are a great way to organise your analytical projects into discrete units that are easier to work on and share.\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the most common issues you will face when using a project someone else has created, or you created previously, is maintaining the required packages to run the project. Knowing what packages are needed to run a particular project isn’t always obvious, and over time packages can change rendering code that once worked unusable.\n{renv} solves this problem by:\n\nkeeping track of the packages that are required for a particular project\nlogging the installed version of all of the packages\nmaintaining a per-project library of packages, so projects don’t interfere with one another\n\nIt’s a good idea to use {renv} for all projects."
  },
  {
    "objectID": "style/project_structure.html#use-rstudio-projects",
    "href": "style/project_structure.html#use-rstudio-projects",
    "title": "Project Structure",
    "section": "",
    "text": "RStudio projects are a great way to organise your analytical projects into discrete units that are easier to work on and share."
  },
  {
    "objectID": "style/project_structure.html#renv",
    "href": "style/project_structure.html#renv",
    "title": "Project Structure",
    "section": "",
    "text": "One of the most common issues you will face when using a project someone else has created, or you created previously, is maintaining the required packages to run the project. Knowing what packages are needed to run a particular project isn’t always obvious, and over time packages can change rendering code that once worked unusable.\n{renv} solves this problem by:\n\nkeeping track of the packages that are required for a particular project\nlogging the installed version of all of the packages\nmaintaining a per-project library of packages, so projects don’t interfere with one another\n\nIt’s a good idea to use {renv} for all projects."
  },
  {
    "objectID": "style/style_guide.html",
    "href": "style/style_guide.html",
    "title": "Style Guide",
    "section": "",
    "text": "On the whole we follow the conventions of the tidyverse style guide\nWe prefer packages to be explicitly namespaced like this dplyr::mutate(...). This is not essential in exploratory data analysis but is mandatory in all production code\nFor readability please insert line breaks in your code at or before column 80.\nWe prefer to avoid loading {tidyverse} because it brings in a lot of packages that are not being used. Again, not essential to follow this in exploratory data analysis but no code that is or will be deployed should ever load {tidyverse}\n\n\n\n\n\nfavour |&gt; over %&gt;%\nfavour .qmd over .rmd\nuse git for all projects, github being the home of all of the project code\nRAP everything\n{styler}\nhttps://style.tidyverse.org/\n{lintr}"
  },
  {
    "objectID": "style/style_guide.html#code-style",
    "href": "style/style_guide.html#code-style",
    "title": "Style Guide",
    "section": "",
    "text": "On the whole we follow the conventions of the tidyverse style guide\nWe prefer packages to be explicitly namespaced like this dplyr::mutate(...). This is not essential in exploratory data analysis but is mandatory in all production code\nFor readability please insert line breaks in your code at or before column 80.\nWe prefer to avoid loading {tidyverse} because it brings in a lot of packages that are not being used. Again, not essential to follow this in exploratory data analysis but no code that is or will be deployed should ever load {tidyverse}"
  },
  {
    "objectID": "style/style_guide.html#unorganised-notes",
    "href": "style/style_guide.html#unorganised-notes",
    "title": "Style Guide",
    "section": "",
    "text": "favour |&gt; over %&gt;%\nfavour .qmd over .rmd\nuse git for all projects, github being the home of all of the project code\nRAP everything\n{styler}\nhttps://style.tidyverse.org/\n{lintr}"
  },
  {
    "objectID": "blogs/posts/2023-04-26-reinstalling-r-packages.html",
    "href": "blogs/posts/2023-04-26-reinstalling-r-packages.html",
    "title": "Reinstalling R Packages",
    "section": "",
    "text": "R 4.3.0 was released last week. Anytime you update R you will probably find yourself in the position where no packages are installed. This is by design - the packages that you have installed may need to be updated and recompiled to work under new versions of R.\nYou may find yourself wanting to have all of the packages that you previously used, so one approach that some people take is to copy the previous library folder to the new versions folder. This isn’t a good idea and could potentially break your R install.\nAnother approach would be to export the list of packages in R before updating and then using that list after you have updated R. This can cause issues though if you install from places other than CRAN, e.g. bioconductor, or from GitHub.\nSome of these approaches are discussed on the RStudio Community Forum. But I prefer an approach of having a “spring clean”, instead only installing the packages that I know that I need.\nI maintain a list of the packages that I used as a gist. Using this, I can then simply run this script on any new R install. In fact, if you click the “raw” button on the gist, and copy that url, you can simply run\nsource(\"https://gist.githubusercontent.com/tomjemmett/c105d3e0fbea7558088f68c65e68e1ed/raw/a1db4b5fa0d24562d16d3f57fe8c25fb0d8aa53e/setup.R\")\nGenerally, sourcing a url is a bad idea - the reason for this is if it’s not a link that you control, then someone could update the contents and run arbritary code on your machine. In this case, I’m happy to run this as it’s my own gist, but you should be mindful if running it yourself!\nIf you look at the script I first install a number of packages from CRAN, then I install packages that only exist on GitHub."
  },
  {
    "objectID": "blogs/posts/2023-04-26_alternative_remotes.html",
    "href": "blogs/posts/2023-04-26_alternative_remotes.html",
    "title": "Alternative remote repositories",
    "section": "",
    "text": "It’s great when someone send’s you a pull request on GitHub to fix bugs or add new features to your project, but you probably always want to check the other persons work in someway before merging that pull request.\nAll of the steps below are intended to be entered via a terminal.\nLet’s imagine that we have a GitHub account called example and a repository called test, and we use https rather than ssh.\n$ git remote get-url origin\n# https://github.com/example/test.git\nNow, let’s say we have someone who has submitted a Pull Request (PR), and their username is friend. We can add a new remote for their fork with\n$ git remote add friend https://github.com/friend/test.git\nHere, I name the remote exactly as per the persons GitHub username for no other reason than making it easier to track things later on. You could name this remote whatever you like, but you will need to make sure that the remote url matches their repository correctly.\nWe are now able to checkout their remote branch. First, we will want to fetch their work:\n# make sure to replace the remote name to what you set it to before\n$ git fetch friend\nNow, hopefully they have commited to a branch with a name that you haven’t used. Let’s say they created a branch called my_work. You can then simply run\n$ git switch friend/my_work\nThis should checkout the my_work branch locally for you.\nNow, if they have happened to use a branch name that you are already using, or more likely, directly commited to their own main branch, you will need to do checkout to a new branch:\n# replace friend as above to be the name of the remote, and main to be the branch\n# that they have used\n# replace their_work with whatever you want to call this branch locally\n$ git checkout friend/main -b their_work\nYou are now ready to run their code and check everything is good to merge!\nFinally, If you want to clean up your local repository you can remove the new branch that you checked out and the new remote with the following steps:\n# switch back to one of your branches, e.g. main\n$ git checkout main\n\n# then remove the branch that you created above\n$ git branch -D their_work\n\n# you can remove the remote\n$ git remote remove friend"
  },
  {
    "objectID": "blogs/posts/2023-03-24_hotfix-with-git.html",
    "href": "blogs/posts/2023-03-24_hotfix-with-git.html",
    "title": "Creating a hotfix with git",
    "section": "",
    "text": "I recently discovered a bug in a code-base which needed to be fixed and deployed back to production A.S.A.P., but since the last release the code has moved on significantly. The history looks something a bit like:\nThat is, we have a tag which is the code that is currently in production (which we need to patch), a number of commits after that tag to main (which were separate branches merged via pull requests), and a current development branch.\nI need to somehow: 1. go back to the tagged release, 2. check that code out, 3. patch that code, 4. commit this change, but insert the commit before all of the new commits after the tag\nThere are at least two ways that I know to do this, one would be with an interactive rebase, but I used a slightly longer method, but one I feel is a little less likely to get wrong.\nBelow are the step’s that I took. One thing I should note is this worked well for my particular issue because the change didn’t cause any merge conflicts later on."
  },
  {
    "objectID": "blogs/posts/2023-03-24_hotfix-with-git.html#fixing-my-codebase",
    "href": "blogs/posts/2023-03-24_hotfix-with-git.html#fixing-my-codebase",
    "title": "Creating a hotfix with git",
    "section": "Fixing my codebase",
    "text": "Fixing my codebase\nFirst, we need to checkout the tag\ngit checkout -b hotfix v0.2.0\nThis creates a new branch called hotfix off of the tag v0.2.0.\nNow that I have the code base checked out at the point I need to fix, I can make the change that is needed, and commit the change\ngit add [FILENAME]\ngit commit -m \"fixes the code\"\n(Obviously, I used the actual file name and gave a better commit message. I Promise 😝)\nNow my code is fixed, I create a new tag for this “release”, as well as push the code to production (this step is omitted here)\ngit tag v0.2.1 -m \"version 0.2.0\"\nAt this point, our history looks something like\n\n\n\n\n\nWhat we want to do is break the link between main and v0.2.0, instead attaching tov0.2.1. First though, I want to make sure that if I make a mistake, I’m not making it on the main branch.\ngit checkout main\ngit checkout -b apply-hotfix\nThen we can fix our history using the rebase command\ngit rebase hotfix\nWhat this does is it rolls back to the point where the branch that we are rebasing (apply-hotfix) and the hotfix branch both share a common commit (v0.2.0 tag). It then applies the commits in the hotfix branch, before reapplying the commits from apply-hotfix (a.k.a. the main branch).\nOne thing to note, if you have any merge conflicts created by your fix, then the rebase will stop and ask you to fix the merge conflicts. There is some information in the GitHub doc’s for [resolving merge conflicts after a Git rebase][2].\n[2]: https://docs.github.com/en/get-started/using-git/resolving-merge-conflicts-after-a-git-rebase\nAt this point, we can check that the commit history looks correct\ngit log v0.2.0..HEAD\nIf we are happy, then we can apply this to the main branch. I do this by renaming the apply-hotfix branch as main. First, you have to delete the main branch to allow us to rename the branch.\ngit branch -D main\ngit branch -m main\nWe also need to update the other branches to use the new main branch\ngit checkout branch\ngit rebase main\nNow, we should have a history like"
  },
  {
    "objectID": "blogs/index.html",
    "href": "blogs/index.html",
    "title": "Data Science Blog",
    "section": "",
    "text": "Reinstalling R Packages\n\n\n\n\n\n\n\ngit\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2023\n\n\nTom Jemmett\n\n\n\n\n\n\n  \n\n\n\n\nAlternative remote repositories\n\n\n\n\n\n\n\ngit\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2023\n\n\nTom Jemmett\n\n\n\n\n\n\n  \n\n\n\n\nCreating a hotfix with git\n\n\n\n\n\n\n\ngit\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2023\n\n\nTom Jemmett\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "TODO"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science @ The Strategy Unit",
    "section": "",
    "text": "This is the home of the Data Science team at The Strategy Unit."
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#introduction",
    "href": "presentations/2023-03-23_collaborative-working/index.html#introduction",
    "title": "Collaborative working",
    "section": "Introduction",
    "text": "Introduction\n\nThis is definitely an art and not a science\nI do not claim to have all, or even most of, the answers\nHow you use these tools is way more important than the tools themselves\nThis is a culture and not a technique"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#costs",
    "href": "presentations/2023-03-23_collaborative-working/index.html#costs",
    "title": "Collaborative working",
    "section": "Costs",
    "text": "Costs\n\nDelay and time\nStress and disagreement\nCommittee thinking\nLearning and effort"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#benefits",
    "href": "presentations/2023-03-23_collaborative-working/index.html#benefits",
    "title": "Collaborative working",
    "section": "Benefits",
    "text": "Benefits\n\n“From each according to their ability”\nLearning\nReproducibility and reduced truck factor\nFun!"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#github-as-an-organising-principle-behind-work",
    "href": "presentations/2023-03-23_collaborative-working/index.html#github-as-an-organising-principle-behind-work",
    "title": "Collaborative working",
    "section": "GitHub as an organising principle behind work",
    "text": "GitHub as an organising principle behind work\n\nA project is just a set of milestones\nA milestone is just a set of issues\nAn issue is just a set of commits\nA commit is just text added and removed"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#the-repo-owner",
    "href": "presentations/2023-03-23_collaborative-working/index.html#the-repo-owner",
    "title": "Collaborative working",
    "section": "The repo owner",
    "text": "The repo owner\n\nReview milestones\nReview issues\n\nDiscuss the issue on the issue- NOT on email!\n\nReview pull requests and get your pull requests reviewed!"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#asynchronous-communication",
    "href": "presentations/2023-03-23_collaborative-working/index.html#asynchronous-communication",
    "title": "Collaborative working",
    "section": "Asynchronous communication",
    "text": "Asynchronous communication\n\nInvolve others before you pull request\nInvolve others when you pull request\nRead issues!\nComment on issues!\nFile issues- suggestions/ bug reports/ questions\n\nNOT in emails"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#asynchronous-work",
    "href": "presentations/2023-03-23_collaborative-working/index.html#asynchronous-work",
    "title": "Collaborative working",
    "section": "Asynchronous work",
    "text": "Asynchronous work\n\nEvery piece of work has an issues associated with it\nEvery piece of work associated with an issue lives on its own branch\nEvery branch is incorporated to the main repo by a pull request\nEvery pull request is reviewed"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#iteration-and-documentation",
    "href": "presentations/2023-03-23_collaborative-working/index.html#iteration-and-documentation",
    "title": "Collaborative working",
    "section": "Iteration and documentation",
    "text": "Iteration and documentation\n\nAnalyse early, analyse often (using RAPs!)\nWrite down what you did\nWrite down what you did but then changed your mind about\nFavour Quarto/ RMarkdown\n\nClean sessions\nDocumentation and graphics"
  },
  {
    "objectID": "presentations/2023-03-23_collaborative-working/index.html#data-and-.gitignore",
    "href": "presentations/2023-03-23_collaborative-working/index.html#data-and-.gitignore",
    "title": "Collaborative working",
    "section": "Data and .gitignore",
    "text": "Data and .gitignore\n\nYour repo needs to be reproducible but also needs to be safe\nThe main branch should be reproducible by anyone at any time\n\nDocument package dependencies (using renv)\nDocument data loads if the data isn’t in the repo"
  },
  {
    "objectID": "presentations/2023-03-09_coffee-and-coding/index.html#which-is-easier-to-read",
    "href": "presentations/2023-03-09_coffee-and-coding/index.html#which-is-easier-to-read",
    "title": "Good Coding Practices",
    "section": "Which is easier to read?",
    "text": "Which is easier to read?\n\nae_attendances|&gt; filter(org_code%in%c(\"RNA\", \"RL4\"))|&gt; mutate(performance=1+breaches/attendances) |&gt;\n    filter(type== 1) |&gt;\n  mutate(met_target=performance&gt;=0.95)\n\nor\n\nae_attendances |&gt;\n  filter(\n    org_code %in% c(\"RNA\", \"RL4\"),\n    type == 1\n  ) |&gt;\n  mutate(\n    performance = 1 + breaches / attendances,\n    met_target = performance &gt;= 0.95\n  )\n\n\n  spending a few seconds to neatly format your code can greatly improve the legibility to future readers, making the intent of the code far clearer, and will make finding bugs easier to spot.\n\n\n  (have you spotted the mistake in the snippets above?)"
  },
  {
    "objectID": "presentations/2023-03-09_coffee-and-coding/index.html#tidyverse-style-guide",
    "href": "presentations/2023-03-09_coffee-and-coding/index.html#tidyverse-style-guide",
    "title": "Good Coding Practices",
    "section": "Tidyverse Style Guide",
    "text": "Tidyverse Style Guide\n\nGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread\n\n\nAll style guides are fundamentally opinionated. Some decisions genuinely do make code easier to use (especially matching indenting to programming structure), but many decisions are arbitrary. The most important thing about a style guide is that it provides consistency, making code easier to write because you need to make fewer decisions.\n\ntidyverse style guide"
  },
  {
    "objectID": "presentations/2023-03-09_coffee-and-coding/index.html#lintr-styler-are-your-new-best-friends",
    "href": "presentations/2023-03-09_coffee-and-coding/index.html#lintr-styler-are-your-new-best-friends",
    "title": "Good Coding Practices",
    "section": "{lintr} + {styler} are your new best friends",
    "text": "{lintr} + {styler} are your new best friends\n\n\n{lintr}\n\n{lintr} is a static code analysis tool that inspects your code (without running it)\nit checks for certain classes of errors (e.g. mismatched { and (’s)\nit warns about potential issues (e.g. using variables that aren’t defined)\nit warns about places where you are not adhering to the code style\n\n\n{styler}\n\n{styler} is an RStudio add in that automatically reformats your code, tidying it up to match the style guide\n99.9% of the time it will give you equivalent code, but there is the potential that it may change the behaviour of your code\nit will overwrite the files that you ask it to run on however, so it is vital to be using version control\na good workflow here is to save your file, “stage” the changes to your file, then run {styler}. You can then revert back to the staged changed if needed."
  },
  {
    "objectID": "presentations/2023-03-09_coffee-and-coding/index.html#what-does-lintr-look-like",
    "href": "presentations/2023-03-09_coffee-and-coding/index.html#what-does-lintr-look-like",
    "title": "Good Coding Practices",
    "section": "What does {lintr} look like?",
    "text": "What does {lintr} look like?\n\n\n\nsource: Good practice for writing R code and R packages\n\nrunning lintr can be done in the console, e.g.\n\nlintr::lintr_dir(\".\")\n\nor via the Addins menu"
  },
  {
    "objectID": "presentations/2023-03-09_coffee-and-coding/index.html#using-styler",
    "href": "presentations/2023-03-09_coffee-and-coding/index.html#using-styler",
    "title": "Good Coding Practices",
    "section": "Using {styler}",
    "text": "Using {styler}\n\nsource: Good practice for writing R code and R packages"
  },
  {
    "objectID": "presentations/2023-03-09_coffee-and-coding/index.html#further-thoughts-on-improving-code-legibility",
    "href": "presentations/2023-03-09_coffee-and-coding/index.html#further-thoughts-on-improving-code-legibility",
    "title": "Good Coding Practices",
    "section": "Further thoughts on improving code legibility",
    "text": "Further thoughts on improving code legibility\n\ndo not let files grow too big\nbreak up logic into separate files, then you can use source(\"filename.R) to run the code in that file\nidealy, break up your logic into separate functions, each function having it’s own file, and then call those functions within your analysis\ndo not repeat yourself - if you are copying and pasting your code then you should be thinking about how to write a single function to handle this repeated logic\n\n\n\n\nview slides at the-strategy-unit.github.io/data_science/presentations"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#what-is-targets",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#what-is-targets",
    "title": "{targets}",
    "section": "What is {targets}?",
    "text": "What is {targets}?\n\nThe targets package is a Make-like pipeline tool for Statistics and data science in R. With targets, you can maintain a reproducible workflow without repeating yourself. targets learns how your pipeline fits together, skips costly runtime for tasks that are already up to date, runs only the necessary computation, supports implicit parallel computing, abstracts files as R objects, and shows tangible evidence that the results match the underlying code and data.\n\n\n\nData analysis can be slow. A round of scientific computation can take several minutes, hours, or even days to complete. After it finishes, if you update your code or data, your hard-earned results may no longer be valid. Unchecked, this invalidation creates chronic Sisyphean loop:\n\n\nLaunch the code.\nWait while it runs.\nDiscover an issue.\nRestart from scratch.\n\n\nsource: The {targets} R package user manual"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#what-is-it-actually-trying-to-do",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#what-is-it-actually-trying-to-do",
    "title": "{targets}",
    "section": "What is it actually trying to do?",
    "text": "What is it actually trying to do?\n\n\nYour analysis is built up of a number of steps that build one on top of another\nbut these steps need to run in a particular order\nsome of these steps may take a long time to run\nso you only want to run the steps that have changed"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#typical-solution",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#typical-solution",
    "title": "{targets}",
    "section": "Typical solution",
    "text": "Typical solution\n\n\nSteps\nYou have a folder with numbered scripts, such as:\n\n1. get data.R\n2. process data.R\n3. produce charts.R\n4. build model.R\n5. report.qmd\n\n\nDownsides\n\n\nit’s easy to accidentally skip a step: what happens if you went from 1 to 3?\nperforming one of the steps may take a long time, so you may want to skip it if it’s already been run… but how do you know that it’s already been run?\nperhaps step 4 doesn’t depend on step 3, but is this obvious that you could skip step 4 if step 3 is updated?\nwhat if someone labels the files terribly, or doesn’t number them at all?\nwhat if the numbers become out of date and are in the wrong order?\ndo you need to create a procedure document that describes what to do, step-by-step?"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#targets-to-the-rescue",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#targets-to-the-rescue",
    "title": "{targets}",
    "section": "{targets} to the rescue?",
    "text": "{targets} to the rescue?\n\n\nUsing the previous example, if we were to create functions for each of the steps (all saved in the folder R/), we can start using targets using the function use_targets() which will create a file called _targets.R.\nWe can then modify the file to match our pipeline, for example:\nNote that:\n\nprocessed_data depends upon raw_data,\nchart and model depend upon processed_data,\nreport depends upon chart and model.\n\nWe can visualise our pipeline using tar_visnetwork().\n\n\nlibrary(targets)\n\ntar_option_set(\n  packages = c(\"tibble\", \"dplyr\", \"ggplot2\"),\n)\n\ntar_source()\n\nlist(\n  tar_target(raw_data, get_data()),\n  tar_target(processed_data, process_data(raw_data)),\n  tar_target(chart, produce_chart(processed_data)),\n  tar_target(model, build_model(processed_data)),\n  tar_target(report, generate_report(chart, model))\n)"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#running-the-pipeline",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#running-the-pipeline",
    "title": "{targets}",
    "section": "Running the pipeline",
    "text": "Running the pipeline\nRunning this pipeline is as simple as: tar_make().\nThis will output the following:\n• start target raw_data\n• built target raw_data [1.05 seconds]\n• start target processed_data\n• built target processed_data [0.03 seconds]\n• start target chart\n• built target chart [0.02 seconds]\n• start target model\n• built target model [0.01 seconds]\n• start target report\n• built target report [0 seconds]\n• end pipeline [1.75 seconds]\n\nRunning tar_make() again will show these step’s being skipped:\n✔ skip target raw_data\n✔ skip target processed_data\n✔ skip target chart\n✔ skip target model\n✔ skip target report\n✔ skip pipeline [0.12 seconds]"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#changing-one-of-the-files",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#changing-one-of-the-files",
    "title": "{targets}",
    "section": "Changing one of the files",
    "text": "Changing one of the files\nIf we change produce_chart.R slightly, this will cause chart and report to be invalidated, but it will skip over the other steps.\n\n\n&gt; targets::tar_make()\n\n✔ skip target raw_data\n✔ skip target processed_data\n• start target chart\n• built target chart [0.03 seconds]\n✔ skip target model\n• start target report\n• built target report [0 seconds]\n• end pipeline [1.71 seconds]"
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#using-the-results-of-our-pipeline",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#using-the-results-of-our-pipeline",
    "title": "{targets}",
    "section": "Using the results of our pipeline",
    "text": "Using the results of our pipeline\nWe can view the results of any step using tar_read() and tar_load(). These will either directly give you the results of a step, or load that step into your environment (as a variable with the same name as the step).\nThis allows us to view intermediate steps as well as the final outputs of our pipelines.\nOne thing you may want to consider doing is as a final step in a pipeline is to generate a quarto document, or save call a function like saveRDS to generate more useful outputs."
  },
  {
    "objectID": "presentations/2023-03-23_coffee-and-coding/index.html#current-examples-of-targets-in-action",
    "href": "presentations/2023-03-23_coffee-and-coding/index.html#current-examples-of-targets-in-action",
    "title": "{targets}",
    "section": "Current examples of {targets} in action",
    "text": "Current examples of {targets} in action\n\ncode used in this presentation\nNHP Inputs (all of the data processing steps are a targets pipeline)\nNHP Strategies (runs Sql scripts to update tables in the data warehouse)\nNHP Model (all of the data extraction, processing, and uploading for the model is a targets pipeline)\nMacmillan on NCDR - Jacqueline has been using {targets} for her current project\n\nThe {targets} documentation is exceptionally detailed and easy to follow, and goes into more complex examples (such as dynamic branching of steps in a pipeline and high performance computing setups)\n\n\n\nview slides at the-strategy-unit.github.io/data_science/presentations"
  },
  {
    "objectID": "presentations/index.html",
    "href": "presentations/index.html",
    "title": "Presentations",
    "section": "",
    "text": "Presentations\n\nWhat is data science?\nCoffee and coding 23rd February 2023\nCoffee and coding 9th March 2023\nCoffee and coding 23rd March 2023"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#welcome-to-coffee-and-coding",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#welcome-to-coffee-and-coding",
    "title": "Coffee and coding intro session",
    "section": "Welcome to coffee and coding",
    "text": "Welcome to coffee and coding\n\nProject demos, showcasing work from a particular project\nMethod demos, showcasing how to use a particular method/tool/package\nSurgery and problem solving sessions\nDefining code standards and SOP"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#what-are-we-trying-to-achieve",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#what-are-we-trying-to-achieve",
    "title": "Coffee and coding intro session",
    "section": "What are we trying to achieve?",
    "text": "What are we trying to achieve?\n\nLegibility\nReproducibility\nAccuracy\nLaziness"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#what-are-some-of-the-fundamental-principles",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#what-are-some-of-the-fundamental-principles",
    "title": "Coffee and coding intro session",
    "section": "What are some of the fundamental principles?",
    "text": "What are some of the fundamental principles?\n\nPredictability, reducing mental load, and reducing truck factor\nMaking it easy to collaborate with yourself and others on different computers, in the cloud, in six months’ time…\nDRY"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#what-is-rap",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#what-is-rap",
    "title": "Coffee and coding intro session",
    "section": "What is RAP",
    "text": "What is RAP\n\na process in which code is used to minimise manual, undocumented steps, and a clear, properly documented process is produced in code which can reliably give the same result from the same dataset\nRAP should be:\n\n\nthe core working practice that must be supported by all platforms and teams; make this a core focus of NHS analyst training\n\nGoldacre review"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#the-road-to-rap",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#the-road-to-rap",
    "title": "Coffee and coding intro session",
    "section": "The road to RAP",
    "text": "The road to RAP\n\nWe’re roughly using NHS Digital’s RAP stages\nThere is an incredibly large amount to learn!\nConfession time! (everything I do not know…)\nYou don’t need to do it all at once\nYou don’t need to do it all at all ever\nEach thing you learn will incrementally help you\nRemember- that’s why we learnt this stuff. Because it helped us. And it can help you too"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#levels-of-rap--baseline",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#levels-of-rap--baseline",
    "title": "Coffee and coding intro session",
    "section": "Levels of RAP- Baseline",
    "text": "Levels of RAP- Baseline\n\nData produced by code in an open-source language (e.g., Python, R, SQL).\nCode is version controlled (see Git basics and using Git collaboratively guides).\nRepository includes a README.md file (or equivalent) that clearly details steps a user must follow to reproduce the code\nCode has been peer reviewed.\nCode is published in the open and linked to & from accompanying publication (if relevant).\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#levels-of-rap--silver",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#levels-of-rap--silver",
    "title": "Coffee and coding intro session",
    "section": "Levels of RAP- Silver",
    "text": "Levels of RAP- Silver\n\nCode is well-documented…\nCode is well-organised following standard directory format\nReusable functions and/or classes are used where appropriate\nPipeline includes a testing framework\nRepository includes dependency information (e.g. requirements.txt, PipFile, environment.yml\nData is handled and output in a Tidy data format\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#levels-of-rap--gold",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#levels-of-rap--gold",
    "title": "Coffee and coding intro session",
    "section": "Levels of RAP- Gold",
    "text": "Levels of RAP- Gold\n\nCode is fully packaged\nRepository automatically runs tests etc. via CI/CD or a different integration/deployment tool e.g. GitHub Actions\nProcess runs based on event-based triggers (e.g., new data in database) or on a schedule\nChanges to the RAP are clearly signposted. E.g. a changelog in the package, releases etc. (See gov.uk info on Semantic Versioning)\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#a-learning-journey-to-get-us-there",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#a-learning-journey-to-get-us-there",
    "title": "Coffee and coding intro session",
    "section": "A learning journey to get us there",
    "text": "A learning journey to get us there\n\nCode style, organising your files\nFunctions and iteration\nGit and GitHub\nPackaging your code\nTesting\nPackage management and versioning"
  },
  {
    "objectID": "presentations/2023-02-23_coffee-and-coding/index.html#how-we-can-help-each-other-get-there",
    "href": "presentations/2023-02-23_coffee-and-coding/index.html#how-we-can-help-each-other-get-there",
    "title": "Coffee and coding intro session",
    "section": "How we can help each other get there",
    "text": "How we can help each other get there\n\nWork as a team!\nCoffee and coding!\nAsk for help!\nDo pair coding!\nGet your code reviewed!\nJoin the NHS-R/ NHSPycom communities"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#what-is-data-science",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#what-is-data-science",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "What is data science?",
    "text": "What is data science?\n\n“A data scientist knows more about computer science than the average statistician, and more about statistics than the average computer scientist”"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#drew-conways-famous-venn-diagram",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#drew-conways-famous-venn-diagram",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Drew Conway’s famous Venn diagram",
    "text": "Drew Conway’s famous Venn diagram\n\nSource"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#around-the-web",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#around-the-web",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Around the web…",
    "text": "Around the web…\n\n\n\nThe difference between a statitician and a data scientist? About $30,000\n… an actual definition of data science. Taking a database and making it do something else. (warning: this quote is me! 😉)\nStatistics done on a Mac"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#what-are-the-skills-of-data-science",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#what-are-the-skills-of-data-science",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "What are the skills of data science?",
    "text": "What are the skills of data science?\n\nAnalysis\n\nML\nStats\nData viz\n\nSoftware engineering\n\nProgramming\nSQL/ data\nDevOps\nRAP"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#what-are-the-skills-of-data-science-1",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#what-are-the-skills-of-data-science-1",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "What are the skills of data science?",
    "text": "What are the skills of data science?\n\nDomain knowledge\n\nCommunication\nProblem formulation\nDashboards and reports"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#ml",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#ml",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "ML",
    "text": "ML\n\nSource"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#inevitable-xkcd",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#inevitable-xkcd",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Inevitable XKCD",
    "text": "Inevitable XKCD\n\n\n\nSource\n\n\nGoogle flu trends"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#stats-and-data-viz",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#stats-and-data-viz",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Stats and data viz",
    "text": "Stats and data viz\n\nML leans a bit more towards atheoretical prediction\nStats leans a bit more towards inference (but they both do both)\nData scientists may use different visualisations\n\nInteractive web based tools\nDashboard based visualisers e.g. {stminsights}"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#software-engineering",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#software-engineering",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Software engineering",
    "text": "Software engineering\n\nProgramming\n\nNo/ low code data science?\n\nSQL/ data\n\nTend to use reproducible automated processes\n\nDevOps\n\nPlan, code, build, test, release, deploy, operate, monitor\n\nRAP\n\nI will come back to this"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#domain-knowledge",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#domain-knowledge",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Domain knowledge",
    "text": "Domain knowledge\n\nDo stuff that matters\n\nThe best minds of my generation are thinking about how to make people click ads. That sucks. Jeffrey Hammerbacher\n\nConvince other people that it matters\nThis is the hardest part of data science\nCommunicate, communicate, communicate!\nMany of you are expert at this"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#reproducibility",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#reproducibility",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nReproducibility in science\nThe $6B spreadsheet error\nGeorge Osbourne’s austerity was based on a spreadsheet error\nFor us, reproducibility also means we can do the same analysis 50 times in one minute\n\nWhich is why I started down the road of data science"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#what-is-rap",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#what-is-rap",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "What is RAP",
    "text": "What is RAP\n\na process in which code is used to minimise manual, undocumented steps, and a clear, properly documented process is produced in code which can reliably give the same result from the same dataset\nRAP should be:\n\n\nthe core working practice that must be supported by all platforms and teams; make this a core focus of NHS analyst training\n\nGoldacre review"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#levels-of-rap--baseline",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#levels-of-rap--baseline",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Levels of RAP- Baseline",
    "text": "Levels of RAP- Baseline\n\nData produced by code in an open-source language (e.g., Python, R, SQL).\nCode is version controlled (see Git basics and using Git collaboratively guides).\nRepository includes a README.md file (or equivalent) that clearly details steps a user must follow to reproduce the code\nCode has been peer reviewed.\nCode is published in the open and linked to & from accompanying publication (if relevant).\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#levels-of-rap--silver",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#levels-of-rap--silver",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Levels of RAP- Silver",
    "text": "Levels of RAP- Silver\n\nCode is well-documented…\nCode is well-organised following standard directory format\nReusable functions and/or classes are used where appropriate\nPipeline includes a testing framework\nRepository includes dependency information (e.g. requirements.txt, PipFile, environment.yml\nData is handled and output in a Tidy data format\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#levels-of-rap--gold",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#levels-of-rap--gold",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Levels of RAP- Gold",
    "text": "Levels of RAP- Gold\n\nCode is fully packaged\nRepository automatically runs tests etc. via CI/CD or a different integration/deployment tool e.g. GitHub Actions\nProcess runs based on event-based triggers (e.g., new data in database) or on a schedule\nChanges to the RAP are clearly signposted. E.g. a changelog in the package, releases etc. (See gov.uk info on Semantic Versioning)\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#the-data-science-unicorn",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#the-data-science-unicorn",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "The data science “Unicorn”",
    "text": "The data science “Unicorn”\n\nThe maybe-mythical data science “Unicorn” has mastered:\n\nDomain knowledge\nStats and ML\nSoftware engineering"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#data-science-is-a-team-sport",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#data-science-is-a-team-sport",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Data science is a team sport",
    "text": "Data science is a team sport\n\nIn my extended DS team I have:\nStats and DevOps (and rabble rousing) [this one is me 😉]\nSQL, data, and training\nDevOps and programming\nText mining, Python, and APIs\nBilingual R/ Python, Shiny dashboards"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#data-science-is-an-mmo",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#data-science-is-an-mmo",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Data science is an MMO",
    "text": "Data science is an MMO\n\nData scientists need help with:\n\nStakeholder communication and engagement\nQualitative analysis\nTranslating models and prediction into the real world\nEvidence review and problem definition"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#data-science-is-an-mmo-1",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#data-science-is-an-mmo-1",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Data science is an MMO",
    "text": "Data science is an MMO\n\nData scientists are an excellent help when you:\n\nNeed a lot of pretty graphs\nNeed the same analysis done 50+ times with different data\nHave too much text and not enough time to analyse it\nWant to carefully document your analysis and make it reproducible\nHave a hideously messy, large dataset that you can’t hack together yourself"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#the-team",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#the-team",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "The team",
    "text": "The team\n\nWe will be organising code review and pair coding sessions\nWe will be running coffee and coding sessions\nWe can be relied on to get very excited about thorny data problems, especially if they involve:\n\nDrawing pretty graphs\nNHS-R and other communities and events\nSpending long hours in a bunker writing open source code\nProcessing text\nDocumenting and version controlling analyses"
  },
  {
    "objectID": "presentations/2023-02-01_what-is-data-science/index.html#note",
    "href": "presentations/2023-02-01_what-is-data-science/index.html#note",
    "title": "Everything you ever wanted to know about data science (but were too afraid to ask)",
    "section": "Note",
    "text": "Note\nAll copyrighted material is reused under Fair Dealing"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#what-is-rap",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#what-is-rap",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "What is RAP",
    "text": "What is RAP\n\na process in which code is used to minimise manual, undocumented steps, and a clear, properly documented process is produced in code which can reliably give the same result from the same dataset\nRAP should be:\n\n\nthe core working practice that must be supported by all platforms and teams; make this a core focus of NHS analyst training\n\nGoldacre review"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#what-are-we-trying-to-achieve",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#what-are-we-trying-to-achieve",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "What are we trying to achieve?",
    "text": "What are we trying to achieve?\n\nLegibility\nReproducibility\nAccuracy\nLaziness"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#what-are-some-of-the-fundamental-principles",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#what-are-some-of-the-fundamental-principles",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "What are some of the fundamental principles?",
    "text": "What are some of the fundamental principles?\n\nPredictability, reducing mental load, and reducing truck factor\nMaking it easy to collaborate with yourself and others on different computers, in the cloud, in six months’ time…\nDRY"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#the-road-to-rap",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#the-road-to-rap",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "The road to RAP",
    "text": "The road to RAP\n\nWe’re roughly using NHS Digital’s RAP stages\nThere is an incredibly large amount to learn!\nConfession time! (everything I do not know…)\nYou don’t need to do it all at once\nYou don’t need to do it all at all ever\nEach thing you learn will incrementally help you\nRemember- that’s why we learnt this stuff. Because it helped us. And it can help you too"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#levels-of-rap--baseline",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#levels-of-rap--baseline",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "Levels of RAP- Baseline",
    "text": "Levels of RAP- Baseline\n\nData produced by code in an open-source language (e.g., Python, R, SQL).\nCode is version controlled (see Git basics and using Git collaboratively guides).\nRepository includes a README.md file (or equivalent) that clearly details steps a user must follow to reproduce the code\nCode has been peer reviewed.\nCode is published in the open and linked to & from accompanying publication (if relevant).\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#levels-of-rap--silver",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#levels-of-rap--silver",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "Levels of RAP- Silver",
    "text": "Levels of RAP- Silver\n\nCode is well-documented…\nCode is well-organised following standard directory format\nReusable functions and/or classes are used where appropriate\nPipeline includes a testing framework\nRepository includes dependency information (e.g. requirements.txt, PipFile, environment.yml\nData is handled and output in a Tidy data format\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#levels-of-rap--gold",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#levels-of-rap--gold",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "Levels of RAP- Gold",
    "text": "Levels of RAP- Gold\n\nCode is fully packaged\nRepository automatically runs tests etc. via CI/CD or a different integration/deployment tool e.g. GitHub Actions\nProcess runs based on event-based triggers (e.g., new data in database) or on a schedule\nChanges to the RAP are clearly signposted. E.g. a changelog in the package, releases etc. (See gov.uk info on Semantic Versioning)\n\nSource: NHS Digital RAP community of practice"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#a-learning-journey-to-get-you-there",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#a-learning-journey-to-get-you-there",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "A learning journey to get you there",
    "text": "A learning journey to get you there\n\nCode style, organising your files\nFunctions and iteration\nGit and GitHub\nPackaging your code\nTesting\nPackage management and versioning"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#how-we-can-help-each-other-get-there",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#how-we-can-help-each-other-get-there",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "How we can help each other get there",
    "text": "How we can help each other get there\n\nWork as a team!\nCoffee and coding!\nAsk for help!\nDo pair coding!\nGet your code reviewed!\nJoin the NHS-R/ NHSPycom communities"
  },
  {
    "objectID": "presentations/2023-03-09_midlands-analyst-rap/index.html#haca",
    "href": "presentations/2023-03-09_midlands-analyst-rap/index.html#haca",
    "title": "RAP- what is it and how can my team start using it effectively?",
    "section": "HACA",
    "text": "HACA\n\nThe first national analytics conference for health and care\nInsight to action!\nJuly 11th and 12th, University of Birmingham\nAccepting abstracts for short and long talks and posters\nAbstract deadline 27th March\nHelp is available (with abstract, poster, preparing presentation…)!"
  }
]